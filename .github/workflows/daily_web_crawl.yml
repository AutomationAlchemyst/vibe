name: Daily Web Crawl

on:
  schedule:
    # Runs at 00:00 UTC, which is 8:00 AM SGT (Singapore Time)
    - cron: '0 0 * * *'
  workflow_dispatch: # Allows manual triggering from the Actions tab

jobs:
  run-web-crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' # Or your preferred Python version

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install feedparser openai python-dotenv gspread google-auth newspaper3k

      - name: Create Google Credentials file
        # Create the credentials file needed by gspread from the GitHub Secret
        # Ensure the GOOGLE_CREDENTIALS secret contains the JSON content.
        run: echo "${{ secrets.GOOGLE_CREDENTIALS }}" > credentials2.json
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

      - name: Run the web crawl script
        run: python webcrawl/web_crawl.py
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          SHEET_ID: ${{ secrets.SHEET_ID }}
          SENDER_EMAIL: ${{ secrets.SENDER_EMAIL }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          # Note: The script loads creds.env, but we are providing secrets directly as env vars.
          # If creds.env contains other necessary variables, add them as secrets and env vars here.
